{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras' has no attribute 'engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-d38ea6ab146f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mvanilla_ae_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\nicon\\OneDrive\\Documents\\Uni - TUM\\Semester2\\ML in CM&S\\Final Project\\vanilla_ae_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mvanilla_ae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_dim\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhl_dim\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \"\"\"\n\u001b[0;32m     50\u001b[0m     \u001b[0mArgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api._v2.keras' has no attribute 'engine'"
     ]
    }
   ],
   "source": [
    "# from sklearn.datasets import make_swiss_roll\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras  \n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras' has no attribute 'engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-6e59f92c1e41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mvanilla_ae_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\nicon\\OneDrive\\Documents\\Uni - TUM\\Semester2\\ML in CM&S\\Final Project\\vanilla_ae_functions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mvanilla_ae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_dim\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhl_dim\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \"\"\"\n\u001b[0;32m     50\u001b[0m     \u001b[0mArgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api._v2.keras' has no attribute 'engine'"
     ]
    }
   ],
   "source": [
    "from vanilla_ae_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.engine.keras_tensor import KerasTensor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and remaining data\n",
    "# X_train, X_remaining = train_test_split(subset_vectors, test_size=0.4, random_state=42)\n",
    "\n",
    "# Split the remaining data into validation and testing sets\n",
    "# X_val, X_test = train_test_split(X_remaining, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to your Word2Vec dataset\n",
    "dataset_path = \"GoogleNews-vectors-negative300.bin.gz\"\n",
    "\n",
    "# Load the Word2Vec model\n",
    "model = KeyedVectors.load_word2vec_format(dataset_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors = model.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_unnormalised = all_vectors[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input(dataset_path: str) -> np.ndarray:\n",
    "    model = KeyedVectors.load_word2vec_format(dataset_path, binary=True)\n",
    "    all_vectors = model.vectors\n",
    "    return all_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in between offer cut down of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors = load_input(\"GoogleNews-vectors-negative300.bin.gz\")[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_abs_input(unnormalised_dataset: np.ndarray) -> np.ndarray:\n",
    "    # Figure out the min value, so to make all vectors positive\n",
    "    min_x_unormalised = min([min(i) for i in unnormalised_dataset])\n",
    "    pos_x_train = unnormalised_dataset+abs(min_x_unormalised)\n",
    "    \n",
    "    # Normalise the data by dividing by the max of the positive data\n",
    "    max_pos_x = max([max(i) for i in pos_x_train])\n",
    "    x_train = pos_x_train/max_pos_x\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalise_abs_input(all_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_ae(input: KerasTensor, x_train: np.ndarray, original_dim: int = 300, hl_dim: int = 2, epochs: int = 25, batch_size: int = 128):\n",
    "    encoded = Dense(hl_dim, activation='relu')(input)\n",
    "    decoded = Dense(original_dim, activation='relu')(encoded)\n",
    "    \n",
    "    autoencoder = Model(input, decoded)\n",
    "\n",
    "    autoencoder.compile(loss=\"binary_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "    autoencoder.fit(x_train, x_train, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: 1 hidden layers, size = 2\n",
    "reference: https://stats.stackexchange.com/questions/345208/optimal-hidden-units-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of neurons at the input layer\n",
    "original_dim = 300  \n",
    "# hidden layer dimension\n",
    "hl_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(original_dim,), name='Encoder_Input_Layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "79/79 [==============================] - 2s 4ms/step - loss: 4.5512\n",
      "Epoch 2/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.4206\n",
      "Epoch 3/25\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 4.4093\n",
      "Epoch 4/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.4054\n",
      "Epoch 5/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.4034\n",
      "Epoch 6/25\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 4.4021\n",
      "Epoch 7/25\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 4.4011\n",
      "Epoch 8/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.4005\n",
      "Epoch 9/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4.3999\n",
      "Epoch 10/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.3995\n",
      "Epoch 11/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4.3992\n",
      "Epoch 12/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4.3990\n",
      "Epoch 13/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4.3988\n",
      "Epoch 14/25\n",
      "79/79 [==============================] - 1s 6ms/step - loss: 4.3986\n",
      "Epoch 15/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4.3985\n",
      "Epoch 16/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.3984\n",
      "Epoch 17/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.3983\n",
      "Epoch 18/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.3982\n",
      "Epoch 19/25\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 4.3982\n",
      "Epoch 20/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.3981\n",
      "Epoch 21/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.3981\n",
      "Epoch 22/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.3980\n",
      "Epoch 23/25\n",
      "79/79 [==============================] - 0s 6ms/step - loss: 4.3980\n",
      "Epoch 24/25\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 4.3979\n",
      "Epoch 25/25\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 4.3979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x1e2b2f0dee0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_ae(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_inputs = Input(shape=(latent_dim,), name='Input_Z_Sampling')\n",
    "latent_inputs = Input(shape=(hl_dim,), name='Input_Z_Sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Given that it is a multilayer perceptron, RELU Activation function\n",
    "reference: https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/ \n",
    "\n",
    "know it is a MLP, as:\n",
    "- MLP : MLP is a basic feedforward neural network where information flows from the input layer through one or more hidden layers to the output layer. classification and regression tasks\n",
    "- CNN : processing grid-like data, such as images or audio spectrograms, learning local patterns and features from input data\n",
    "- RNN : process sequential or time-series data, where the order of data points matters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 3ms/step - loss: 8.1067 - accuracy: 0.0028\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8.1067 - accuracy: 0.0028\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 8.1067 - accuracy: 0.0028\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8.1067 - accuracy: 0.0028\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8.1067 - accuracy: 0.0028\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 8.1067 - accuracy: 0.0028\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8.1067 - accuracy: 0.0028\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 8.1067 - accuracy: 0.0028\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 8.1067 - accuracy: 0.0028\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 8.1067 - accuracy: 0.0028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e2a3f693d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = Dense(hl_dim, activation='relu')(input)\n",
    "decoded = Dense(original_dim, activation='relu')(encoded)  # Adjusted to match input dimension\n",
    "autoencoder = Model(input, decoded)\n",
    "autoencoder.compile(loss=\"binary_crossentropy\", \n",
    "                    optimizer=Adam(learning_rate=0.001),\n",
    "                    metrics=[\"accuracy\"])\n",
    "autoencoder.fit(x_train, x_train, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "encoded_data = autoencoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1493772\n"
     ]
    }
   ],
   "source": [
    "# Measuring the error \n",
    "mse = np.mean(np.square(x_train - encoded_data))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-06\n"
     ]
    }
   ],
   "source": [
    "# Determining the accuracy doesn't really make sense\n",
    "acc = np.mean(x_train == encoded_data)\n",
    "print(acc)\n",
    "# Cross validation during testing\n",
    "# Runtime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
